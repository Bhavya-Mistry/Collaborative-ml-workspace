# -*- coding: utf-8 -*-
"""ToxicCommentClassifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B-PULK9MoQX6ltW4sHJIbZifu1xmuUMI
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import classification_report, accuracy_score, f1_score

from google.colab import drive
drive.mount('/content/drive')

# Load from Google Drive or local
df = pd.read_csv("/content/drive/MyDrive/train.csv")  # Change this path if needed

# Show shape and preview
print("Shape of dataset:", df.shape)
df.head()

df.describe()

df.info()

df.isnull().sum()

#take only label columns
x = df.iloc[:, 2:].sum()
x

# take label columns and sum it column wise
rowsums = df.iloc[:,2:].sum(axis=1)
rowsums

no_label_count = 0

for i, count in rowsums.items():
  if count == 0:
    no_label_count += 1

print("Total numberof comments:", len(df))
print("Number of comments without any label:", no_label_count)
print("Total labels", x.sum())

plt.figure(figsize=(6,4))
ax = sns.barplot(x=x.index, y=x.values, alpha=0.8, palette="magma")
plt.title("Label Distribution")
plt.ylabel("Count", fontsize=12)
plt.xlabel("Label", fontsize=12)
plt.show()

# Check label distribution
labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
label_counts = df[labels].sum().sort_values(ascending=False)

# Plot label distribution
plt.figure(figsize=(10, 5))
sns.barplot(x=label_counts.index, y=label_counts.values, palette="magma")
plt.title("Label Distribution in Jigsaw Toxic Comment Dataset")
plt.ylabel("Count")
plt.grid(axis='y')
plt.show()

# Multi-label statistics
print("Average number of labels per comment:", df[labels].sum(axis=1).mean())
print("Comments with no labels:", (df[labels].sum(axis=1) == 0).sum())

plt.figure(figsize=(6, 4))
ax = sns.countplot(x=rowsums.values, alpha=0.8, palette="magma")
plt.title('Labels per Comment')
plt.ylabel('# of Occurences')
plt.xlabel('# of Labels')

plt.show()

"""# **Data Preprocessing**"""

# Define text cleaning function
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^a-z\s]', '', text)  # Remove non-letters
    text = re.sub(r'\s+', ' ', text).strip()  # Normalize spaces
    return text

# Apply cleaning
df['clean_comment'] = df['comment_text'].apply(clean_text)
df[['comment_text', 'clean_comment']].head()

df = df.drop(columns=['id'], axis=1)
df.head()

# remove stopwords
from nltk.corpus import stopwords
stopwords = set(stopwords.words('english'))

def remove_stopwords(text):
    no_stopword_text = [w for w in text.split() if not w in stopwords]
    return " ".join(no_stopword_text)

# stemming
from nltk.stem import SnowballStemmer
stemmer = SnowballStemmer('english')
def stemming(sentence):
    stemmed_sentence = ""
    for word in sentence.split():
        stemmed_word = stemmer.stem(word)
        stemmed_sentence += stemmed_word + " "

    stemmed_sentence = stemmed_sentence.strip()
    return stemmed_sentence

df['clean_comment'] = df['clean_comment'].apply(lambda x: remove_stopwords(x))
df['clean_comment'] = df['clean_comment'].apply(lambda x: stemming(x))

# Vectorize the clean text using TF-IDF
vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
X = vectorizer.fit_transform(df['clean_comment'])

# Target labels
y = df[labels]

print("Shape of feature matrix:", X.shape)
print("Shape of target labels:", y.shape)

# 80/20 split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Logistic Regression

OneVsRestClassifier does the following:

Trains one logistic regression model for each column of y_train.

Each model learns to predict "yes" or "no" for just one label.

During prediction, it runs all models and combines their results into a full multi-label prediction.
"""

# Use Logistic Regression with One-vs-Rest strategy for multi-label classification
model = OneVsRestClassifier(LogisticRegression(solver='liblinear'))
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate performance
print("Accuracy:", accuracy_score(y_test, y_pred))
print("F1 Score (Micro):", f1_score(y_test, y_pred, average='micro'))
print("F1 Score (Macro):", f1_score(y_test, y_pred, average='macro'))

# Classification report
print("\nClassification Report:\n")
print(classification_report(y_test, y_pred, target_names=labels))

# F1-score per label
f1_scores = f1_score(y_test, y_pred, average=None)

# Plot
plt.figure(figsize=(10, 5))
sns.barplot(x=labels, y=f1_scores, palette="magma")
plt.title("F1 Score per Toxic Label")
plt.ylabel("F1 Score")
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

"""#SVM"""

from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier

# Define the model
svm_model = OneVsRestClassifier(LinearSVC())

# Train the model
svm_model.fit(X_train, y_train)

# Predict on test set
y_pred_svm = svm_model.predict(X_test)

# Evaluate
from sklearn.metrics import classification_report, f1_score, accuracy_score

print("SVM Classifier Results")
print("-----------------------")
print("Accuracy:", accuracy_score(y_test, y_pred_svm))
print("F1 Score (micro):", f1_score(y_test, y_pred_svm, average='micro'))
print("F1 Score (macro):", f1_score(y_test, y_pred_svm, average='macro'))

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred_svm, target_names=y.columns))

# Plot F1-scores per label
f1_scores_svm = f1_score(y_test, y_pred_svm, average=None)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 5))
sns.barplot(x=y.columns, y=f1_scores_svm, palette="magma")
plt.title("F1 Score for Each Label (SVM Classifier)")
plt.ylabel("F1 Score")
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

"""#  Naive bayes

"""

# Step 1: Import Naive Bayes Classifier
from sklearn.naive_bayes import MultinomialNB

# Step 2: Train Naive Bayes Model
nb_model = OneVsRestClassifier(MultinomialNB())
nb_model.fit(X_train, y_train)

# Step 3: Predict with the trained Naive Bayes model
y_nb_pred = nb_model.predict(X_test)

# Step 4: Evaluate Naive Bayes Model
from sklearn.metrics import classification_report, accuracy_score, f1_score

print("Naive Bayes Accuracy:", accuracy_score(y_test, y_nb_pred))
print("Naive Bayes F1 Score (Micro):", f1_score(y_test, y_nb_pred, average='micro'))
print("Naive Bayes F1 Score (Macro):", f1_score(y_test, y_nb_pred, average='macro'))

print("\nNaive Bayes Classification Report:\n")
print(classification_report(y_test, y_nb_pred, target_names=y.columns))

# Step 5: Visualize F1 Scores for Naive Bayes Model
f1_scores_nb = f1_score(y_test, y_nb_pred, average=None)

plt.figure(figsize=(10, 5))
sns.barplot(x=y.columns, y=f1_scores_nb, palette="magma")

plt.title("Naive Bayes F1 Score for Each Toxic Label")
plt.ylabel("F1 Score")
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()