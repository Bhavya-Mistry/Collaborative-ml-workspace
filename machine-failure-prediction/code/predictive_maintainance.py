# -*- coding: utf-8 -*-
"""Predictive-maintainance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RFhARwAU5yD8sNmEWu06j8cGr6njUsf4
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import confusion_matrix,accuracy_score

from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM, Activation
from keras.callbacks import EarlyStopping

import matplotlib.pyplot as plt
plt.style.use('ggplot')
# %matplotlib inline

df = pd.read_csv("PM_train.txt", sep = ' ',header=None)

df.shape

df.head()

"""These CMAPSS data files are space-separated.

But the files have extra spaces at the end of each line, so when pandas reads them with sep=' ', it creates extra empty columns at the end so we drop those two of them below.

"""

df = pd.read_csv("PM_train.txt", sep = ' ',header=None).drop([26,27], axis=1)

df.shape

df.head()

"""Lets now rename our columns to id, cycle, setting1, setting2, setting3, sensor1, sensor2,.....,sensor21"""

col_names = ['id','cycle','setting1','setting2','setting3','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21']

df.columns=col_names

df.head()

df_test = pd.read_csv("PM_test.txt", sep=' ', header=None).drop([26,27],axis = 1)

df_test.columns = col_names

df_test.head()

df_test.shape

df_truth = pd.read_csv("truth.txt", sep = ' ', header=None)

df_truth.head()

"""Here also same case so we drop on column"""

df_truth = pd.read_csv("truth.txt", sep = ' ', header=None).drop([1],axis=1)
df_truth.head()

df_truth.columns = ['more']
df_truth['id'] = df_truth.index+1

df_truth.head()

"""Grouping by ```id``` for maximum value of ```cycle``` to find RUL (remaning useful life)"""

rul = pd.DataFrame(df_test.groupby('id')['cycle'].max()).reset_index()

rul.head()

rul.columns = ['id', 'max']

rul.head()

"""* ```df_truth``` Contains the Remaining Useful Life (RUL) of each test engine at the last cycle in the test data.

* The column ```more``` in ```df_truth``` means "how many more cycles until failure" from the last point in ```df_test```
"""

df_truth.head()

"""Actucal failure cycle or Remaning to failure **RTF** is given by:

currentcycle + remaning useful life

i.e.

 ```df_truth['more']``` + ```rul['max']```
"""

df_truth['rtf'] = df_truth['more']+rul['max']
df_truth.head()

"""We needed ```more``` just to calculate ```rtf``` now we can drop it"""

df_truth.drop('more', axis = 1, inplace = True)

df_test = df_test.merge(df_truth, on=['id'], how='left')

"""In test, the engines have not failed yet — we only get partial data.
So we don’t know from the test file when each engine will fail.

**That info is given separately in truth.txt as:**

“Engine X will fail Y cycles after the last recorded cycle.”

so we first find **RTF**

then for **TTF**:

* actual life cycle or **RTF** - current cycle


and we can then remove rtf


"""

df_test['ttf']=df_test['rtf'] - df_test['cycle']
df_test.drop('rtf', axis=1, inplace=True)
df_test.head()

"""Now lets calculate **TTF** for training set too.

Here the machine runs until it actually fails

so for TTF we find maximum of cycle for particular machine id and then we apply :
* ttf = max (cycle) - cycle

for all the rows and a point will come for where the ttf will be zero, hence failure!
"""

df['ttf'] = df.groupby(['id'])['cycle'].transform(max)-df['cycle']
df.head()

df['ttf'].unique()

"""Now lets apply a threshold for converting this label into binary classification column (with 0s and 1s)


so lets say we want the thresold to be 'x' then
* ttf < 30  = failure
* ttf > 30 = okay
"""

df_train1=df.copy()
df_test1=df_test.copy()
period=30
df_train1['label_bc'] = df_train1['ttf'].apply(lambda x: 1 if x <= period else 0)
df_test1['label_bc'] = df_test1['ttf'].apply(lambda x: 1 if x <= period else 0)

df_train1.head()

df_test1.head()

df_train1['label_bc'].unique()

df_test1['label_bc'].unique()

features_col_name=['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11',
                   's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']
target_col_name='label_bc'

sc=MinMaxScaler()
df_train1[features_col_name]=sc.fit_transform(df_train1[features_col_name])
df_test1[features_col_name]=sc.transform(df_test1[features_col_name])

df_train1.head()

"""# Lets try Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

X_train = df_train1[features_col_name]
Y_train = df_train1[target_col_name]

X_test = df_test1[features_col_name]
Y_test = df_test1[target_col_name]

# Initialize the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model on the training data
rf_model.fit(X_train, Y_train)

# Make predictions on the test data
y_pred_default = rf_model.predict(X_test)

# Accuracy
accuracy = accuracy_score(Y_test, y_pred_default)
print(f'Accuracy: {accuracy * 100:.2f}%')

# Confusion Matrix
cm = confusion_matrix(Y_test, y_pred_default)
print('Confusion Matrix:')
print(cm)

"""# With Hyperparameter Tuning

"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],           # Number of trees
    'max_depth': [10, 20, None],               # Max depth of tree
    'min_samples_split': [2, 5, 10],           # Min samples to split an internal node
    'min_samples_leaf': [1, 2, 4],             # Min samples at a leaf node
    'bootstrap': [True, False]                 # Sampling method
}

rf = RandomForestClassifier(random_state=42)

grid_search = GridSearchCV(estimator=rf,
                           param_grid=param_grid,
                           cv=3,
                           n_jobs=-1,
                           verbose=2,
                           scoring='accuracy')

grid_search.fit(X_train, Y_train)

print("Best Parameters:\n", grid_search.best_params_)
print("Best Accuracy: ", grid_search.best_score_)

best_rf_model = grid_search.best_estimator_
y_pred_tuned = best_rf_model.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("Test Accuracy:", accuracy_score(Y_test, y_pred_tuned))
print("Confusion Matrix:\n", confusion_matrix(Y_test, y_pred_tuned))
print("Classification Report:\n", classification_report(Y_test, y_pred_tuned))